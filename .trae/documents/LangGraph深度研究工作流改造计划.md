## 总览
- 将现有 ResearchAgent 以 LangGraph 状态机重构为“输入解析→任务拆解→参数推断→初始检索→缺口分析→跟进检索→聚合分析→可信度评估→报告生成→评估预警→异常恢复”的闭环工作流。
- 保留现有工具与内存（WebSearch、Scraper、Chroma、DoubaoEmbeddings），新增分层记忆、参数推断引擎、可视化与指标监控。
- 移除用户可配置参数界面，仅接收 `query`，所有策略由智能引擎自动推断。

## 目标与约束
- 研究深度自动化：命题复杂度→研究深度（basic/standard/comprehensive）。
- 三阶段检索：广度优先建框架→向量缺口分析→知识图谱定向深掘。
- 并行子任务≥3，单次研究≤5分钟，内存≤2GB。
- 完整自文档化：所有节点生成可解释日志，报告可追溯论证链。

## LangGraph 集成架构
- 新增 `src/workflows/research_graph.py`：构建 `StateGraph`，统一节点、边与恢复策略。
- 节点装饰器统一日志：封装 `log_event(node, inputs, outputs, rationale, metrics)`，写入结构化事件流。
- Runner：在 API 后台任务中启动图执行，支持并行分支与超时控制。

## 状态机设计（≥7）
1. 输入解析（InputParsing）：语义解析、逻辑重构、意图抽取、变量归一。
2. 任务拆解（TaskDecomposition）：将复杂命题拆为可执行子研究任务序列与依赖图。
3. 参数推断（ParameterInference）：推断检索策略、分析深度、报告详细程度。
4. 初始检索（InitialRetrieval）：广度优先多源采样，构建知识框架与候选来源。
5. 缺口分析（GapAnalysis）：向量相似度+主题聚类，识别知识盲区与证据缺口。
6. 跟进检索（FollowUpRetrieval）：基于知识图谱对缺口进行定向深度查询与抓取。
7. 聚合分析（SynthesisAnalysis）：多视角合并、主题/矛盾/空白提取、要点摘要。
8. 可信度评估（CredibilityEvaluation）：来源可信度评分矩阵与结论置信度计算。
9. 报告生成（ReportGeneration）：结构化报告+图谱可视化+方法学文档。
10. 评估预警（EvaluationMonitoring）：覆盖率、来源多样性、闭合度监控与预警。
11. 异常恢复（AutoRecovery）：节点失败自动重试/跳过/降级与状态回溯。

## 模块改造
- `src/agents/research_agent.py`：
  - 抽取节点逻辑为纯函数：解析、拆解、检索、分析、评估、报告。
  - 保留 `WebSearchTool`/`ScraperTool` 调用，增加对并行与节流的支持。
- `src/api/api_router.py`：
  - `POST /api/v1/research` 仅接收 `query`；移除 `max_sources/depth` 等可配置参数。
  - 后台任务改为调度 `ResearchGraphRunner.run(query)`，返回 `task_id`。
- `main.py`：
  - 引入 LangGraph 初始化与日志路由；保留现有 logging。

## 输入处理与参数推断
- 输入解析：
  - 语法/语义正则、LLM 辅助指代消解与约束抽取。
  - 输出：命题范式、实体/关系、研究维度与边界。
- 复杂度评估：
  - 指标：实体数、关系度、跨学科性、时效性、数据型/理论型。
  - 映射：`basic/standard/comprehensive` 深度等级。
- 参数推断引擎：
  - 检索策略：广度采样数、跟进深掘层级、迭代轮次。
  - 分析深度：摘要→证据对齐→反证→一致性校验。
  - 报告详细度：执行摘要/标准报告/技术附录。

## 智能检索三阶段
- 初始信息收集：
  - 广度优先：新闻/百科/论文索引/行业报告等多源采样（≥5源）。
  - 上下文维护：会话状态记录主题、子任务与来源概览。
- 缺口分析：
  - 向量相似度（Chroma+DoubaoEmbeddings）+主题聚类，找出空白与冲突。
  - 形成缺口列表与优先级。
- 跟进检索：
  - 基于知识图谱的定向深掘：沿关系与主题缺口展开，抓取关键证据。
  - 迭代次数≥3（覆盖率保障）。

## 记忆管理与压缩
- 分层记忆架构：
  - 短期记忆（STM）：当前会话状态与中间产物（任务图、候选来源、阶段摘要）。
  - 长期记忆（LTM）：跨会话知识图谱（实体/关系/来源元数据）+ Chroma 文档向量。
- 记忆压缩算法：
  - 主题簇摘要（基于相似度聚类的代表性样本+LLM 摘要）。
  - 去重与截断：重复段落合并、长度上限裁剪、Top-K 保留。
  - 元数据保留：来源、时间戳、可信度、节点路径。

## 报告生成与可视化
- 结构化报告：
  - 章节：执行摘要、主题与要点、知识图谱、来源可信度矩阵、矛盾与空白、方法学文档、论证链追溯。
- 图谱可视化：
  - Markdown 内嵌 Mermaid（graph TD）生成多维度知识图谱；HTML 模板渲染同构图。
- 可信度评分矩阵：
  - 以表格展示域名类型/出版类型/同行评审/时效性等维度评分与加权结果。
- 论证逻辑链追溯：
  - 每个结论附带证据链条（来源→片段→分析节点→结论），可定位到日志事件ID。
- 方法学文档自动生成：
  - 描述检索策略、参数推断、分析流程、评估指标与限制。

## 评估体系与质量预警
- 指标：
  - 知识覆盖率：检索迭代次数≥3，主题空白占比≤阈值。
  - 来源多样性：权威来源（论文/机构/政府/教材/行业）≥5。
  - 论证完整性：证据链闭合度≥90%。
- 预警：
  - 任一指标低于阈值，生成 `quality_warning`，报告标注“需进一步研究”，并建议追加子任务。

## 日志与可追溯
- 结构化事件流：
  - 字段：`event_id, node, stage, inputs_hash, outputs_hash, rationale, metrics, timestamp`。
  - 写入：统一 Logger + 文件，必要时分流到 `logs/stages.log`。
- 全节点可追溯：
  - 报告中增加事件ID与节点名的反向索引，支持追溯。

## 性能与并行
- 并行：
  - 初始检索与跟进检索对不同子任务并行（并行度≥3）。
- 时间预算：
  - 图运行设定 `deadline=300s`；节点超时重试/跳过；逐步降级（减少抓取深度、压缩摘要）。
- 内存预算：
  - 控制每轮抓取与入库文档数量、启用压缩与去重；外部向量库定期GC。

## 改动清单（文件级）
- 新增：`src/workflows/research_graph.py`（LangGraph 状态机与 Runner）。
- 修改：
  - `src/agents/research_agent.py`：拆分与纯化节点函数、并行支持、质量指标输出。
  - `src/memory/memory_manager.py`：STM/LTM 分层、压缩与图谱存储（JSON 邻接表）。
  - `src/generation/report_generator.py`：Mermaid 图谱、可信度矩阵、方法学文档与追溯锚点。
  - `src/api/api_router.py`：请求只接收 `query`，驱动 `ResearchGraphRunner`。
  - `config.py`：新增图谱与日志配置、开关与阈值。
  - `frontend/index.html`：渲染 Mermaid/矩阵与预警提示。
- 依赖：加入 `langgraph` 与 `jinja2`（已有）、保守采用内建 JSON 存储，避免引入重型图数据库。

## 验证方案
- 单元测试：
  - 参数推断引擎、记忆压缩、可信度矩阵、评估阈值。
- 集成测试：
  - 三阶段检索闭环（迭代≥3）、并行执行、异常恢复。
- 端到端：
  - API 调用 5 分钟内完成，报告含图谱/矩阵/追溯；日志事件全链路可检索。

## 迁移与兼容
- 保留旧 API 的 `task_id`/历史接口；报告格式向后兼容，新增章节按开关显示。
- 配置默认禁用重型特性（如深度抓取），由参数引擎在高复杂度命题时打开。

请确认以上计划；确认后我将开始分批次落地上述改造并提交可验证的实现与测试。